{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrJkT8lg7QYre1pZu01Vms"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSDQHwMxpXMu",
        "outputId": "5dc6935d-bee9-46c3-c613-4ab49a9c823d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n"
          ]
        }
      ],
      "source": [
        "pip install requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse, urljoin\n"
      ],
      "metadata": {
        "id": "iUbRkm_0qGEO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_url_status(url):\n",
        "    \"\"\"https://www.formula1.com\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=5)\n",
        "        return response.status_code\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error with {url}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "TKBX4MJ9qGI3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_links_from_website(url):\n",
        "    \"\"\"https://www.instagram.com\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=5)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        links = set()  # Use a set to avoid duplicates\n",
        "        for anchor in soup.find_all('a', href=True):\n",
        "            link = urljoin(url, anchor['href'])\n",
        "            # Parse the URL to handle only valid links\n",
        "            parsed_link = urlparse(link)\n",
        "            if parsed_link.scheme in [\"http\", \"https\"]:\n",
        "                links.add(link)\n",
        "        return links\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Failed to retrieve or parse {url}: {e}\")\n",
        "        return set()\n"
      ],
      "metadata": {
        "id": "Oe89N8foqGL-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scan_urls(urls):\n",
        "    \"\"\"https://ae5212b3dd1e33233d0c21045872a6fa.serveo.net\"\"\"\n",
        "    for url in urls: # This line had an extra space, causing the indentation error.\n",
        "        status = check_url_status(url)\n",
        "        if status:\n",
        "            print(f\"URL: {url} returned status code: {status}\")\n",
        "        else:\n",
        "            print(f\"URL: {url} is not reachable.\")"
      ],
      "metadata": {
        "id": "2qbA3xpExz2A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # List of websites or URLs to scan\n",
        "    websites_to_scan = [\n",
        "        \"https://www.formula1.com\",\n",
        "        \"https://www.instagram.com\",\n",
        "        \"https://ae5212b3dd1e33233d0c21045872a6fa.serveo.net\"  # Example of a broken link\n",
        "    ]\n",
        "\n",
        "    print(\"Scanning URLs...\")\n",
        "    scan_urls(websites_to_scan)\n",
        "\n",
        "    # Optionally, extract and scan links from a given website\n",
        "    target_website = \"https://ae5212b3dd1e33233d0c21045872a6fa.serveo.net\"\n",
        "    print(f\"\\nExtracting links from {target_website}...\")\n",
        "    extracted_links = extract_links_from_website(target_website)\n",
        "\n",
        "    print(f\"\\nFound {len(extracted_links)} links on {target_website}:\")\n",
        "    for link in extracted_links:\n",
        "        print(link)\n",
        "\n",
        "    print(\"\\nScanning extracted links...\")\n",
        "    scan_urls(extracted_links)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dA0jTnBNwunO",
        "outputId": "2472433e-9951-45e4-e5a4-b654e54ee44a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning URLs...\n",
            "URL: https://www.formula1.com returned status code: 200\n",
            "URL: https://www.instagram.com returned status code: 200\n",
            "URL: https://ae5212b3dd1e33233d0c21045872a6fa.serveo.net returned status code: 502\n",
            "\n",
            "Extracting links from https://ae5212b3dd1e33233d0c21045872a6fa.serveo.net...\n",
            "\n",
            "Found 0 links on https://ae5212b3dd1e33233d0c21045872a6fa.serveo.net:\n",
            "\n",
            "Scanning extracted links...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b2qG0sFqyJFZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}